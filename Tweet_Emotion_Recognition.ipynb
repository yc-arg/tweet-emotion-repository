{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cprXxkrMxIgT"
   },
   "source": [
    "## Task 2: Setup and Imports\n",
    "\n",
    "1. Installing Hugging Face's nlp package\n",
    "2. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2k0RoxiLzU8n",
    "outputId": "3cb82d9f-1a2b-4bbc-c906-b6064cdf4f49"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets fsspec huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5agZRy-45i0g",
    "outputId": "369cdee3-bd5e-417f-b5f1-4601b3548d2d"
   },
   "outputs": [],
   "source": [
    "!pip install nlp\n",
    "#nlp is old version of datasets so we'll use datasets\n",
    "!pip install datasets\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKFjWz6e5eiH",
    "outputId": "6e781092-b582-488b-a269-03612443ba65"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import random\n",
    "\n",
    "# we'll pass the history object that we get after model training in tensorflow to this function\n",
    "# then this function is going to plot the accuracy, the validation accuracy, the loss and the validation laws for that training\n",
    "def show_history(h):\n",
    "    epochs_trained = len(h.history['loss'])\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    #accuracy\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
    "\n",
    "    #validation accuracy\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
    "\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    #loss\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
    "\n",
    "    #validation loss\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# use confusion matrix from sklearn and calculate our predictions against the ground truth\n",
    "def show_confusion_matrix(y_true, y_pred, classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sp = plt.subplot(1, 1, 1)\n",
    "    ctx = sp.matshow(cm)\n",
    "    plt.xticks(list(range(0, 6)), labels=classes)\n",
    "    plt.yticks(list(range(0, 6)), labels=classes)\n",
    "    plt.colorbar(ctx)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('Using TensorFlow version', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JsBpezExIga"
   },
   "source": [
    "## Task 3: Importing Data\n",
    "\n",
    "1. Importing the Tweet Emotion dataset\n",
    "2. Creating train, validation and test sets\n",
    "3. Extracting tweets and labels from the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449,
     "referenced_widgets": [
      "a2c72336b0664188924885ec892bd0b3",
      "1f55e234640441d8990cf2995092b7c0",
      "4285fd9291c44ff0bdda116de2678cb5",
      "f962ca71dcae4a31bbdcaa50a7624dbe",
      "3bbc1cc1f09940a4a9574d3b7959cd78",
      "73443dccf5c041bb98c9edc684c46304",
      "81867ca9e7d246e490e89d9481040118",
      "236642e18c79467f82f0dc166bdca22e",
      "6f0d0dc356cc4b068c0a0938b98397a1",
      "8ec1d39b54184130b14dcdb80c55ceb7",
      "105fc0144d424bdb8d1272ed2802ef91",
      "ef145e26a85c49afba81d0c5aa94d996",
      "c03c06fcf9b744c2b6aed1ef11ea3853",
      "e4c17ba145614375aa2625d54db88eda",
      "f6c9393ce0e94ea4956c1126efe1d93c",
      "5afafa00640e4abbb2a1fd21d9417e2c",
      "52ad5f30349a40cb858f646647ec7be9",
      "0d0d663b032f4b7693dc3fdc5e7c321b",
      "3e2417b0eacc4119ac0cde194d728fe3",
      "3d68bb5e9d074c4fa3e139243d1831e4",
      "e4cb6db8202e42168adb64427fc09b48",
      "4f1d318fc7cb48bb90d8eac344d11368",
      "d2433cd5e3284d3aaac6ff5aa7ad2b29",
      "e271e37b35564de8bb8795ea533ae402",
      "697063945cd0486d9f80056a3a3caea2",
      "276dcb3caa5044b3847b70d00fd1d119",
      "3439a1fd5fcf4fb69dbfa216ace8ee5b",
      "df979955272b4f11b1e816b7ea593971",
      "18a19b0f017d4c35b34c55a2b8d84956",
      "c86025b622cb4e0b8ea8345ad788e9a4",
      "5a46e7afebac48eb97614f825649f0a1",
      "a3d30da7feb941f6bbd90435ecd8c266",
      "e2840505653f4b299c41bc06b1c62a12",
      "1d4560287ffc4e64a4453a706e6b75fc",
      "39e6efe5b8444774b27a00645d2e45df",
      "f3082e56092d4ef5b367367122e551d2",
      "7b8a7eede0574c8bbe6f8f1a9a77d7b1",
      "686e20fe2f3443a88d4a514d8045000a",
      "7202542ca20a4c7c92e6ad1fa25afe5f",
      "e7b0f06e829e46d9b7201eba7d0c81bf",
      "2916811a903d4d1d86bc816f6cc21234",
      "2b59bb3e34ea47ce818dd5fb98f9fbaf",
      "ae1de3ca90054b0996248a37271a26b5",
      "2ca44f970a934dbb88a22a5e95e0d991",
      "76b1f75c34af441196905547998fc973",
      "5ee13a42008e4428aa3910d44cab05f1",
      "18a0bb591ae942598126d86c80abc53e",
      "57841ebbb13242949d232467b67d7c27",
      "e3a2b4a45e2e43a3a522c5dd2d57406f",
      "76aa91ec51b141e5bfd3e8d2a0d031a9",
      "d058ee4e26aa43cead442b529fc7ad26",
      "82bdd705bf054db69e34354b5a47a1ac",
      "fd36dcfd928a47a0b2857dc912097883",
      "7b394aa72b0743ef872b1259f4651ed4",
      "b811650242f043e1ab7718331fa3904d",
      "505fbc750d0041159beeb556d844ab84",
      "3f3b2bf96d75415ea1982a0780b126ae",
      "d9d07570547f4f429d51f7af9892fd2b",
      "d8f1b60f52af4c82b850e5c012e26f2d",
      "57c7b18878244e8fb3e837dfa362ee43",
      "40a1ada836184e6b899fec5141ba59bb",
      "56650b401d0144b49d4dd3c9ef8be5a6",
      "7e287f6a92b346aeb3be0cd97dfb9325",
      "52616cd261c345cc8f5be86a9f79b370",
      "97d625a8529743be97d53f87bb2abe11",
      "7eee4136e0c746fe8709921acfa00b81",
      "c58c4907356048b3a9395d9a111b9495",
      "7b0474d887a74c7ea9b203d918e45213",
      "35221e37307141b3a91bf747c3fc6eaa",
      "8c307b4433a34fa69073affe30dd24ad",
      "fe933d05d2464385890d579a5cf69c34",
      "273343511ac14e95adebde4d2e70f84a",
      "37c4cf0da88b4023960ce41b12bf172a",
      "5fa9874ec3644ee49cca8a7859f01193",
      "6180968d808a4fd5ba39419accceddec",
      "7d0039e4586b455ba9ae4fc8af84ec2e",
      "160ce151ab4a419e9bef8ac6bf22b9e3"
     ]
    },
    "id": "0YHOvjAu5eiL",
    "outputId": "fd6b420e-cbd1-4a70-c513-9e29af1cb25d"
   },
   "outputs": [],
   "source": [
    "# we'll use hugging face nlp module, datasets is new version of nlp\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2s0h541FxIgc",
    "outputId": "5d02d77f-e067-4118-a030-f5261734d560"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7eCnxU25eiN"
   },
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "val = dataset['validation']\n",
    "test = dataset['test']\n",
    "\n",
    "# Label decoder (as labels are in in but we need them in string)\n",
    "label_names = dataset['train'].features['label'].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDYXMfZy5eiP"
   },
   "outputs": [],
   "source": [
    "def get_tweet(data):\n",
    "  tweets = [x['text'] for x in data]\n",
    "  labels = [label_names(x['label']) for x in data]  # decode integer label to string\n",
    "  return tweets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeq3-vSB5eiR"
   },
   "outputs": [],
   "source": [
    "tweets,labels = get_tweet(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHD3Tk0J5eiU",
    "outputId": "7c9bd92a-1508-47bd-9195-06486b8a4f5a"
   },
   "outputs": [],
   "source": [
    "tweets[1], labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcAflLv6xIgp"
   },
   "source": [
    "## Task 4: Tokenizer\n",
    "\n",
    "1. Tokenizing the tweets (break sentences into words and convert those words into numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfX5-ResxIgq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lAO37ka3mtS"
   },
   "source": [
    "<li> create tokenizer object from Tokenizer class which we just imported. </li>\n",
    "<li> we will use <b>10000(num_words)</b> most frequently used words from our corpus.</li>\n",
    "<li>we will set an  out of vocabulary token <b>(oov_token)</b> to a string which is unlikely to be present in our corpus <b>('UNK')</b></li>\n",
    "\n",
    "So, we are going to use most frequently used 10000 words from our corpus and anything taht is not present in those most frequently used 10000 words is tokenized/represented as the token 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cckUvwBo5eif"
   },
   "outputs": [],
   "source": [
    "# create corpus of all the words in a dataset and give each unique word a unique corresponding token\n",
    "tokenizer = Tokenizer(num_words = 10000, oov_token = '<UNK>')\n",
    "\n",
    "#create mapping from the words to numeric tokens\n",
    "tokenizer.fit_on_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kS3L6vNv6PhX",
    "outputId": "19fb60d3-5682-4b21-c587-85651eeb7f56"
   },
   "outputs": [],
   "source": [
    "#Example of what the tokenizer is doing\n",
    "print(tweets[0])\n",
    "tokenizer.texts_to_sequences([tweets[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Bqm7b2xIgu"
   },
   "source": [
    "## Task 5: Padding and Truncating Sequences\n",
    "\n",
    "1. Checking length of the tweets\n",
    "2. Creating padded sequences\n",
    "\n",
    "we need to pad or even truncate the sequences as the lengths of tweets are not same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "mLvf_WFZxIgu",
    "outputId": "bc9a891a-4bf9-49a8-a15f-aac76543b9e9"
   },
   "outputs": [],
   "source": [
    "lengths = [len(t.split(' ')) for t in tweets]\n",
    "plt.hist(lengths, bins = len(set(lengths))) #no. of bins set to number of unique lengths we have in our dataset\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMiV52Vh8cDA"
   },
   "source": [
    "<li> Any tweet which is more than 50 words long, we will chop them off and we'll simply truncate them </li>\n",
    "<li> Any tweets which is less than 50 words long, we'll pad those sequences with just zeros</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOi5lIE3xIgx"
   },
   "outputs": [],
   "source": [
    "maxlen = 50\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI4L-nJC_7VS"
   },
   "source": [
    "Now, we'll define a function called get sequences which we will use to get sequences for our different sets\n",
    "\n",
    "<li><b>truncating = 'post'</b> and <b>padding = 'post'</b> means truncating and padding will happen at the end of the sequence. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9J_Iemf5eiq"
   },
   "outputs": [],
   "source": [
    "def get_sequences(tokenizer, tweets):\n",
    "  sequences = tokenizer.texts_to_sequences(tweets)\n",
    "  padded = pad_sequences(sequences, truncating = 'post', padding = 'post', maxlen = maxlen)\n",
    "  return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eglH77ky5ei0"
   },
   "outputs": [],
   "source": [
    "padded_train_seq = get_sequences(tokenizer,tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGR473HA5ei7",
    "outputId": "ec28c5df-039d-4389-e864-1a902aa4dee5"
   },
   "outputs": [],
   "source": [
    "padded_train_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BURhOX_KxIg8"
   },
   "source": [
    "## Task 6: Preparing the Labels\n",
    "\n",
    "1. Creating classes to index and index to classes dictionaries\n",
    "2. Converting text labels to numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SufT2bpD5ejE",
    "outputId": "0c21ab17-16d2-410a-8390-b08a18cec510"
   },
   "outputs": [],
   "source": [
    "classes = set(labels) #creates a set of unique labels from our training set\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "rpwzL88I7YSm",
    "outputId": "fb32dd86-584b-42d4-dd7f-932a3caae6d1"
   },
   "outputs": [],
   "source": [
    "# visualize number of examples we have to different classes\n",
    "plt.hist(labels, bins=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSQ-RZFmCdac"
   },
   "source": [
    "clearly there is a class imbalance. we ignore that for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHuhi2MUCmu9"
   },
   "source": [
    "We'll now create dictionaries to convert the names of the classes to corresponding numeric values and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNLF6rXL5ejN"
   },
   "outputs": [],
   "source": [
    "class_to_index = dict((c,i) for i,c in enumerate(classes))\n",
    "index_to_class = dict((v,k) for k,v in class_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_08InVyM5ejc",
    "outputId": "41c0c580-2296-4ad9-f4c0-64a2176a1d90"
   },
   "outputs": [],
   "source": [
    "class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpeDoA6gxIhE",
    "outputId": "5d198ad3-3b13-4806-8e2f-385a2b7c6c9b"
   },
   "outputs": [],
   "source": [
    "index_to_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9T68dNJDQOC"
   },
   "source": [
    "We'll create a function to convert names to ids or numberic values and labels will return a numpy array which will have the numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jq0WJYsP5ejR"
   },
   "outputs": [],
   "source": [
    "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v15KnrNC5ejW",
    "outputId": "36c53360-46fa-43bd-f0c7-36bfa6a544a9"
   },
   "outputs": [],
   "source": [
    "train_labels = names_to_ids(labels)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-v0Mnh8xIhP"
   },
   "source": [
    "## Task 7: Creating the Model\n",
    "\n",
    "1. Creating the model\n",
    "2. Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpewXxPQ5eji",
    "outputId": "3e4c412c-72da-4057-d34d-a0193d608a2e"
   },
   "outputs": [],
   "source": [
    "# we'll use sequencial class from keras\n",
    "# we pass a list of layers in the bracket after sequential to create our model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qWiz5TTiPIF"
   },
   "source": [
    "**10000** input dimension and **16** output dimension\n",
    "\n",
    "*   since we're using lstm layer inside bidirectional layer, the context in LSTM can go both left to right and right to left\n",
    "* in dense layer, **6** for the  6 classes that we have\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "f4NJ8u-DtQqC",
    "outputId": "dfb7436e-712c-458b-cfb9-1d34208550b6"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HST_CHjxIhR"
   },
   "source": [
    "## Task 8: Training the Model\n",
    "\n",
    "1. Preparing a validation set\n",
    "2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff7F3hCK5ejm"
   },
   "outputs": [],
   "source": [
    "val_tweets, val_labels = get_tweet(val)\n",
    "val_seq = get_sequences(tokenizer, val_tweets)\n",
    "val_labels = names_to_ids(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlMKaZ3H5ejr",
    "outputId": "d9bdb818-4c45-4016-bdda-eac2060f5281"
   },
   "outputs": [],
   "source": [
    "val_tweets[0], val_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzBqnWQ-5ejw",
    "outputId": "81a13227-e0aa-427f-ca02-c5b2626d95ed"
   },
   "source": [
    "# h = model.fit(\n",
    "    padded_train_seq, train_labels,\n",
    "    validation_data = (val_seq, val_labels),\n",
    "    epochs = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdsJyMTLxIhX"
   },
   "source": [
    "## Task 9: Evaluating the Model\n",
    "\n",
    "1. Visualizing training history\n",
    "2. Prepraring a test set\n",
    "3. A look at individual predictions on the test set\n",
    "4. A look at all predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "ENCfvXeLxIhX",
    "outputId": "c7cd0aac-3757-4bf0-943a-bab20b6d856b"
   },
   "outputs": [],
   "source": [
    "show_history(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWuzoz8uxIha"
   },
   "outputs": [],
   "source": [
    "test_tweets, test_labels = get_tweet(test)\n",
    "test_seq = get_sequences(tokenizer, test_tweets)\n",
    "test_labels = names_to_ids(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vRVJ_2SxIhc",
    "outputId": "952c69bb-7d95-4f2f-8b9a-36fac537415c"
   },
   "outputs": [],
   "source": [
    "_ = model.evaluate(test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rh638vHG5ej6",
    "outputId": "4f17a4f4-a8c0-44f0-d53e-6885020c46a5"
   },
   "outputs": [],
   "source": [
    "i = random.randint(0, len(test_labels)-1)\n",
    "\n",
    "print(\"Sentence:\", test_tweets[i])\n",
    "print(\"Emotion:\", index_to_class[test_labels[i]])\n",
    "\n",
    "p = model.predict(np.expand_dims(test_seq[i], axis=0))[0]\n",
    "pred_class = index_to_class[np.argmax(p).astype('uint8')]\n",
    "\n",
    "print('Predicted Emotion:', pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHl5SVCFxIhh",
    "outputId": "8a061483-dbe0-449c-8cf3-61ef44b9b0fa"
   },
   "outputs": [],
   "source": [
    "#preds = model.predict_classes(test_seq)\n",
    "preds = np.argmax(model.predict(test_seq), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "NC8YQ0OexIhj",
    "outputId": "402ecce6-0813-4731-9061-0351e5d005cf"
   },
   "outputs": [],
   "source": [
    "show_confusion_matrix(test_labels, preds, list(classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
